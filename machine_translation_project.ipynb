{"cells":[{"cell_type":"code","execution_count":null,"id":"a5226e7a","metadata":{"id":"a5226e7a","outputId":"2a34a51d-00c4-4e2e-eaee-293267c7b11c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: keras in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (2.8.0)\r\n"]}],"source":["!pip install keras"]},{"cell_type":"code","execution_count":null,"id":"768491e3","metadata":{"id":"768491e3","outputId":"33cc9373-84ef-4f20-ff15-f3d4127a62be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (2.8.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: six>=1.12.0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.44.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (4.0.1)\n","Requirement already satisfied: setuptools in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (52.0.0.post20210125)\n","Requirement already satisfied: numpy>=1.20 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.20.1)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.19.4)\n","Requirement already satisfied: wrapt>=1.11.0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied: h5py>=2.9.0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n","Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.8.0.dev2021122109)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.24.0)\n","Requirement already satisfied: libclang>=9.0.1 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (13.0.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: gast>=0.2.1 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: astunparse>=1.6.0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=1.12 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.0)\n","Requirement already satisfied: markdown>=2.6.8 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.25.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.4)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.1.1)\n"]}],"source":["!pip install tensorflow"]},{"cell_type":"code","execution_count":null,"id":"c579b6d2","metadata":{"id":"c579b6d2","outputId":"1e9d5a5e-7489-48ff-fb19-dc9aaa355155"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting package metadata (current_repodata.json): done\n","Solving environment: done\n","\n","## Package Plan ##\n","\n","  environment location: /Users/paschalis/opt/anaconda3/envs/keras_env\n","\n","  added / updated specs:\n","    - keras\n","\n","\n","The following NEW packages will be INSTALLED:\n","\n","  keras              pkgs/main/noarch::keras-2.6.0-pyhd3eb1b0_0\n","\n","The following packages will be SUPERSEDED by a higher-priority channel:\n","\n","  ca-certificates    pkgs/main::ca-certificates-2022.3.29-~ --> anaconda::ca-certificates-2020.10.14-0\n","  certifi            pkgs/main::certifi-2021.10.8-py38hecd~ --> anaconda::certifi-2020.6.20-py38_0\n","  openssl              pkgs/main::openssl-1.1.1n-hca72f7f_0 --> anaconda::openssl-1.1.1h-haf1e3a3_0\n","\n","\n","Preparing transaction: done\n","Verifying transaction: done\n","Executing transaction: done\n","\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["conda install -c anaconda keras"]},{"cell_type":"code","execution_count":null,"id":"e9199098","metadata":{"id":"e9199098","outputId":"05ba3a42-6aae-450a-c4a9-68b6c054bf3f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting package metadata (current_repodata.json): done\n","Solving environment: done\n","\n","## Package Plan ##\n","\n","  environment location: /Users/paschalis/opt/anaconda3/envs/keras_env\n","\n","  added / updated specs:\n","    - keras\n","\n","\n","The following packages will be SUPERSEDED by a higher-priority channel:\n","\n","  ca-certificates    pkgs/main::ca-certificates-2022.3.29-~ --> anaconda::ca-certificates-2020.10.14-0\n","  certifi            pkgs/main::certifi-2021.10.8-py38hecd~ --> anaconda::certifi-2020.6.20-py38_0\n","  openssl              pkgs/main::openssl-1.1.1n-hca72f7f_0 --> anaconda::openssl-1.1.1h-haf1e3a3_0\n","\n","\n","Preparing transaction: done\n","Verifying transaction: done\n","Executing transaction: done\n","\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["conda install -c anaconda keras"]},{"cell_type":"code","execution_count":null,"id":"9c4e3175","metadata":{"id":"9c4e3175","outputId":"f25b745e-503a-407a-a68d-01a679a13daa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'keras'...\n","remote: Enumerating objects: 49487, done.\u001b[K\n","remote: Total 49487 (delta 0), reused 0 (delta 0), pack-reused 49487\u001b[K\n","Receiving objects: 100% (49487/49487), 22.90 MiB | 995.00 KiB/s, done.\n","Resolving deltas: 100% (37840/37840), done.\n"]}],"source":["!git clone https://github.com/keras-team/keras.git"]},{"cell_type":"code","execution_count":null,"id":"8952e149","metadata":{"id":"8952e149","outputId":"1081ac93-3b7f-4940-85c6-5b20641a7296"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting package metadata (current_repodata.json): done\n","Solving environment: done\n","\n","## Package Plan ##\n","\n","  environment location: /Users/paschalis/opt/anaconda3/envs/keras_env\n","\n","  added / updated specs:\n","    - numpy\n","\n","\n","The following packages will be downloaded:\n","\n","    package                    |            build\n","    ---------------------------|-----------------\n","    intel-openmp-2021.4.0      |    hecd8cb5_3538         961 KB\n","    libcxx-12.0.0              |       h2f01273_0         805 KB\n","    mkl-service-2.4.0          |   py38h9ed2024_0          45 KB\n","    mkl_fft-1.3.1              |   py38h4ab4a9b_0         165 KB\n","    mkl_random-1.2.2           |   py38hb2f4e1b_0         273 KB\n","    numpy-1.21.2               |   py38h4b4dc7a_0          23 KB\n","    numpy-base-1.21.2          |   py38he0bd621_0         4.6 MB\n","    ------------------------------------------------------------\n","                                           Total:         6.8 MB\n","\n","The following NEW packages will be INSTALLED:\n","\n","  blas               pkgs/main/osx-64::blas-1.0-mkl\n","  intel-openmp       pkgs/main/osx-64::intel-openmp-2021.4.0-hecd8cb5_3538\n","  mkl                pkgs/main/osx-64::mkl-2021.4.0-hecd8cb5_637\n","  mkl-service        pkgs/main/osx-64::mkl-service-2.4.0-py38h9ed2024_0\n","  mkl_fft            pkgs/main/osx-64::mkl_fft-1.3.1-py38h4ab4a9b_0\n","  mkl_random         pkgs/main/osx-64::mkl_random-1.2.2-py38hb2f4e1b_0\n","  numpy              pkgs/main/osx-64::numpy-1.21.2-py38h4b4dc7a_0\n","  numpy-base         pkgs/main/osx-64::numpy-base-1.21.2-py38he0bd621_0\n","\n","The following packages will be UPDATED:\n","\n","  ca-certificates    anaconda::ca-certificates-2020.10.14-0 --> pkgs/main::ca-certificates-2022.3.29-hecd8cb5_0\n","  certifi                anaconda::certifi-2020.6.20-py38_0 --> pkgs/main::certifi-2021.10.8-py38hecd8cb5_2\n","  libcxx                          anaconda::libcxx-10.0.0-1 --> pkgs/main::libcxx-12.0.0-h2f01273_0\n","  openssl               anaconda::openssl-1.1.1h-haf1e3a3_0 --> pkgs/main::openssl-1.1.1n-hca72f7f_0\n","\n","\n","\n","Downloading and Extracting Packages\n","numpy-1.21.2         | 23 KB     | ##################################### | 100% \n","numpy-base-1.21.2    | 4.6 MB    | ##################################### | 100% \n","mkl_fft-1.3.1        | 165 KB    | ##################################### | 100% \n","intel-openmp-2021.4. | 961 KB    | ##################################### | 100% \n","mkl_random-1.2.2     | 273 KB    | ##################################### | 100% \n","libcxx-12.0.0        | 805 KB    | ##################################### | 100% \n","mkl-service-2.4.0    | 45 KB     | ##################################### | 100% \n","Preparing transaction: done\n","Verifying transaction: done\n","Executing transaction: done\n","\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["conda install numpy"]},{"cell_type":"code","execution_count":null,"id":"a94050d7","metadata":{"id":"a94050d7","outputId":"1daaa33b-fc1d-4eb4-87b5-bd34f0034b13"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting package metadata (current_repodata.json): done\n","Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n","Collecting package metadata (repodata.json): done\n","Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n","\n","PackagesNotFoundError: The following packages are not available from current channels:\n","\n","  - tensorflow=2.2.1\n","\n","Current channels:\n","\n","  - https://repo.anaconda.com/pkgs/main/osx-64\n","  - https://repo.anaconda.com/pkgs/main/noarch\n","  - https://repo.anaconda.com/pkgs/r/osx-64\n","  - https://repo.anaconda.com/pkgs/r/noarch\n","\n","To search for alternate channels that may provide the conda package you're\n","looking for, navigate to\n","\n","    https://anaconda.org\n","\n","and use the search bar at the top of the page.\n","\n","\n","\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["conda install tensorflow=2.2.1"]},{"cell_type":"code","execution_count":null,"id":"f1ac80c9","metadata":{"id":"f1ac80c9"},"outputs":[],"source":["from platform import python_version"]},{"cell_type":"code","execution_count":null,"id":"9feccd05","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"9feccd05","executionInfo":{"status":"ok","timestamp":1649148653093,"user_tz":-120,"elapsed":240,"user":{"displayName":"Paschalis Agapitos","userId":"16267825236843228607"}},"outputId":"292329cb-20f3-4cf6-9ed4-d818166f2d69"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'3.7.13'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["python_version()"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zogJ_kHi7jjy","executionInfo":{"status":"ok","timestamp":1649148842422,"user_tz":-120,"elapsed":1697,"user":{"displayName":"Paschalis Agapitos","userId":"16267825236843228607"}},"outputId":"23d79e48-858d-4a98-d200-088bc1b1a574"},"id":"zogJ_kHi7jjy","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"id":"ef09b6b0","metadata":{"id":"ef09b6b0"},"outputs":[],"source":["# UNCOMMENT THE TWO LINES BELOW IF YOU ARE GETTING ERRORS ON A MAC\n","import os \n","os.environ['KMP_DUPLICATE_LIB_OK']='True'"]},{"cell_type":"code","execution_count":null,"id":"44a24529","metadata":{"id":"44a24529"},"outputs":[],"source":["import numpy as np\n","import re"]},{"cell_type":"code","execution_count":null,"id":"54c25666","metadata":{"id":"54c25666"},"outputs":[],"source":["from tensorflow import keras\n","# Add Dense to the imported layers\n","from keras.layers import Input, LSTM, Dense\n","from keras.models import Model"]},{"cell_type":"markdown","id":"5799dce8","metadata":{"id":"5799dce8"},"source":["Note: If we want to load a python file with some code inside, we can use the command `%load python_file.py`. \n","\n","When we run this command it will immediately comment the `%load` magic function and it'll output the code in this file.\n","\n","If we want to ru the file we can use the magic function `%run pythonfile.py`. **Not recommended** since diferrent editos tend to apply different identation to the lines. An efficient approach is to load the file, go through the code line by line, fix the identation mistakes and then run it through the current editor (in our case: Jupyter Notebook).\n","\n","[Can i open .py file in Jupyter Notebook?](https://www.reddit.com/r/learnpython/comments/8zzz1q/can_i_open_py_file_in_jupyter_notebook/) (comment from the user: julsmanbr).\n"]},{"cell_type":"code","execution_count":null,"id":"c011f8fc","metadata":{"id":"c011f8fc"},"outputs":[],"source":["# %load preprocessing.py\n","\n","# Importing our translations\n","# for example: \"spa.txt\" or \"spa-eng/spa.txt\"\n","data_path = \"/content/drive/MyDrive/NLP/C_A_Machine_Translation_Project/CodeAcademy_Project/machine_translation_project/ell.txt\"\n","# data acquired from:\n","# http://www.manythings.org/anki/\n","\n","# Defining lines as a list of each line\n","with open(data_path, 'r', encoding='utf-8') as f:\n","    lines = f.read().split('\\n')\n","\n","# Building empty lists to hold sentences\n","input_docs = []\n","target_docs = []\n","# Building empty vocabulary sets\n","input_tokens = set()\n","target_tokens = set()\n","\n","# Adjust the number of lines so that\n","# preprocessing doesn't take too long for you\n","for line in lines[:2000]:\n","    # Input and target sentences are separated by tabs\n","    input_doc, target_doc = line.split('\\t')[:2]\n","    # Appending each input sentence to input_docs\n","    input_docs.append(input_doc)\n","# target doc is the greek translation \n","# and input doc is the english input\n","\n","# text = \"Paschalis\\tAgapitos\"\n","# name, last_name = text.split(\"\\t\")[:2]\n","# print(name);print(last_name);\n","\n","    target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n","  # Redefine target_doc below\n","  # and append it to target_docs:\n","    target_doc = '<START> ' + target_doc + ' <END>'\n","    target_docs.append(target_doc)\n","\n","  # Now we split up each sentence into words\n","  # and add each unique word to our vocabulary set\n","    for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n","    # Add your code here:\n","        if token not in input_tokens:\n","            input_tokens.add(token)\n","    for token in target_doc.split():\n","    # print(token)\n","    # And here:\n","        if token not in target_tokens:\n","              target_tokens.add(token)\n","\n","input_tokens = sorted(list(input_tokens))\n","target_tokens = sorted(list(target_tokens))\n","\n","# Create num_encoder_tokens and num_decoder_tokens:\n","num_encoder_tokens = len(input_tokens)\n","num_decoder_tokens = len(target_tokens)\n","# print(num_encoder_tokens);print(num_decoder_tokens)\n","\n","max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n","max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n","#print(max_encoder_seq_length);print(max_decoder_seq_length)\n","\n","input_features_dict = dict(\n","    [(token, i) for i, token in enumerate(input_tokens)])\n","target_features_dict = dict(\n","    [(token, i) for i, token in enumerate(target_tokens)])\n","# print(input_features_dict);print(target_features_dict)\n","\n","reverse_input_features_dict = dict(\n","    (i, token) for token, i in input_features_dict.items())\n","reverse_target_features_dict = dict(\n","    (i, token) for token, i in target_features_dict.items())\n","# print(reverse_input_features_dict);print(reverse_target_features_dict)\n","\n","encoder_input_data = np.zeros(\n","    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n","    dtype='float32')\n","decoder_input_data = np.zeros(\n","    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","decoder_target_data = np.zeros(\n","    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n","    \n","    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n","    # Assign 1. for the current line, timestep, & word\n","    # in encoder_input_data:\n","        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n","\n","    for timestep, token in enumerate(target_doc.split()):\n","        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n","        if timestep > 0:\n","              decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1.\n","\n","# print out those value here:\n","print(list(input_features_dict.keys())[:50],\n","      reverse_target_features_dict[50],\n","      len(input_tokens))"]},{"cell_type":"code","source":[""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SEyXXDF76_rv","executionInfo":{"status":"ok","timestamp":1649148723426,"user_tz":-120,"elapsed":15676,"user":{"displayName":"Paschalis Agapitos","userId":"16267825236843228607"}},"outputId":"15eb1739-89fb-4a77-8101-8ba3fb2f9334"},"id":"SEyXXDF76_rv","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"id":"6d909d23","metadata":{"id":"6d909d23"},"outputs":[],"source":["# np1 = np.zeros((5,5,5), dtype='float32') #row, column, number of zero arrays"]},{"cell_type":"markdown","id":"cda33925","metadata":{"id":"cda33925"},"source":["### Explanation of the regex expression that was used to redefine the target_docs:\n","`[\\w']+|[^\\s\\w]`:\n","\n","- `\\w`: **Word**: matches any word word character (alphanumeric and underscore).\n","- `'`: **Character**: matches a \" character (char code 39).\n","- `+`: **Quantifier**: matches one or more of the preceding token.\n","- `|`: **Alternation**: acts like the boolean OR. Matches the expression before or after the `|`.\n","- `[^]`: **Negated set** which means that the regex expression will match everything except from what was defined inside the set.\n","- `\\s`: **Whitespace**: matches any whitespace character (spaces, tabs, line breaks).\n","- `\\w`: **Word**: Matches any word character (alphanumeric and undeerscore)."]},{"cell_type":"code","execution_count":null,"id":"e02da2fb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e02da2fb","executionInfo":{"status":"ok","timestamp":1649154394626,"user_tz":-120,"elapsed":625631,"user":{"displayName":"Paschalis Agapitos","userId":"16267825236843228607"}},"outputId":"feadffdf-fe7a-41f9-b1c7-cbf4193dbdd1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model summary:\n","\n","Model: \"model_9\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_13 (InputLayer)          [(None, None, 791)]  0           []                               \n","                                                                                                  \n"," input_14 (InputLayer)          [(None, None, 1397)  0           []                               \n","                                ]                                                                 \n","                                                                                                  \n"," lstm_6 (LSTM)                  [(None, 400),        1907200     ['input_13[0][0]']               \n","                                 (None, 400),                                                     \n","                                 (None, 400)]                                                     \n","                                                                                                  \n"," lstm_7 (LSTM)                  [(None, None, 400),  2876800     ['input_14[0][0]',               \n","                                 (None, 400),                     'lstm_6[0][1]',                 \n","                                 (None, 400)]                     'lstm_6[0][2]']                 \n","                                                                                                  \n"," dense_3 (Dense)                (None, None, 1397)   560197      ['lstm_7[0][0]']                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 5,344,197\n","Trainable params: 5,344,197\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","\n","\n","\n","Epoch 1/50\n","35/35 [==============================] - 16s 370ms/step - loss: 1.5983 - accuracy: 0.0985 - val_loss: 1.6576 - val_accuracy: 0.1294\n","Epoch 2/50\n","35/35 [==============================] - 12s 346ms/step - loss: 1.3804 - accuracy: 0.1253 - val_loss: 1.6739 - val_accuracy: 0.1221\n","Epoch 3/50\n","35/35 [==============================] - 12s 348ms/step - loss: 1.3376 - accuracy: 0.1326 - val_loss: 1.6589 - val_accuracy: 0.1414\n","Epoch 4/50\n","35/35 [==============================] - 12s 344ms/step - loss: 1.2953 - accuracy: 0.1410 - val_loss: 1.7158 - val_accuracy: 0.1226\n","Epoch 5/50\n","35/35 [==============================] - 12s 351ms/step - loss: 1.2573 - accuracy: 0.1463 - val_loss: 1.6482 - val_accuracy: 0.1492\n","Epoch 6/50\n","35/35 [==============================] - 12s 348ms/step - loss: 1.2115 - accuracy: 0.1555 - val_loss: 1.6449 - val_accuracy: 0.1527\n","Epoch 7/50\n","35/35 [==============================] - 12s 345ms/step - loss: 1.1690 - accuracy: 0.1659 - val_loss: 1.6524 - val_accuracy: 0.1538\n","Epoch 8/50\n","35/35 [==============================] - 12s 343ms/step - loss: 1.1378 - accuracy: 0.1697 - val_loss: 1.6737 - val_accuracy: 0.1591\n","Epoch 9/50\n","35/35 [==============================] - 12s 348ms/step - loss: 1.1036 - accuracy: 0.1741 - val_loss: 1.7210 - val_accuracy: 0.1450\n","Epoch 10/50\n","35/35 [==============================] - 12s 350ms/step - loss: 1.0671 - accuracy: 0.1781 - val_loss: 1.6589 - val_accuracy: 0.1577\n","Epoch 11/50\n","35/35 [==============================] - 12s 343ms/step - loss: 1.0411 - accuracy: 0.1802 - val_loss: 1.6562 - val_accuracy: 0.1685\n","Epoch 12/50\n","35/35 [==============================] - 12s 342ms/step - loss: 0.9981 - accuracy: 0.1850 - val_loss: 1.6508 - val_accuracy: 0.1647\n","Epoch 13/50\n","35/35 [==============================] - 12s 347ms/step - loss: 0.9742 - accuracy: 0.1863 - val_loss: 1.6843 - val_accuracy: 0.1604\n","Epoch 14/50\n","35/35 [==============================] - 12s 349ms/step - loss: 0.9353 - accuracy: 0.1899 - val_loss: 1.7191 - val_accuracy: 0.1547\n","Epoch 15/50\n","35/35 [==============================] - 12s 351ms/step - loss: 0.9077 - accuracy: 0.1929 - val_loss: 1.6449 - val_accuracy: 0.1719\n","Epoch 16/50\n","35/35 [==============================] - 12s 346ms/step - loss: 0.8791 - accuracy: 0.1943 - val_loss: 1.6742 - val_accuracy: 0.1668\n","Epoch 17/50\n","35/35 [==============================] - 12s 344ms/step - loss: 0.8535 - accuracy: 0.1968 - val_loss: 1.6966 - val_accuracy: 0.1623\n","Epoch 18/50\n","35/35 [==============================] - 12s 346ms/step - loss: 0.8276 - accuracy: 0.1992 - val_loss: 1.6923 - val_accuracy: 0.1668\n","Epoch 19/50\n","35/35 [==============================] - 12s 346ms/step - loss: 0.8034 - accuracy: 0.2027 - val_loss: 1.6941 - val_accuracy: 0.1708\n","Epoch 20/50\n","35/35 [==============================] - 12s 348ms/step - loss: 0.7916 - accuracy: 0.2033 - val_loss: 1.6867 - val_accuracy: 0.1735\n","Epoch 21/50\n","35/35 [==============================] - 12s 345ms/step - loss: 0.7649 - accuracy: 0.2061 - val_loss: 1.7284 - val_accuracy: 0.1715\n","Epoch 22/50\n","35/35 [==============================] - 12s 348ms/step - loss: 0.7441 - accuracy: 0.2091 - val_loss: 1.7145 - val_accuracy: 0.1694\n","Epoch 23/50\n","35/35 [==============================] - 12s 349ms/step - loss: 0.7326 - accuracy: 0.2087 - val_loss: 1.6855 - val_accuracy: 0.1760\n","Epoch 24/50\n","35/35 [==============================] - 12s 347ms/step - loss: 0.7040 - accuracy: 0.2117 - val_loss: 1.7339 - val_accuracy: 0.1692\n","Epoch 25/50\n","35/35 [==============================] - 12s 347ms/step - loss: 0.6898 - accuracy: 0.2123 - val_loss: 1.7548 - val_accuracy: 0.1659\n","Epoch 26/50\n","35/35 [==============================] - 12s 346ms/step - loss: 0.6739 - accuracy: 0.2138 - val_loss: 1.8094 - val_accuracy: 0.1590\n","Epoch 27/50\n","35/35 [==============================] - 12s 347ms/step - loss: 0.6526 - accuracy: 0.2161 - val_loss: 1.7344 - val_accuracy: 0.1741\n","Epoch 28/50\n","35/35 [==============================] - 12s 343ms/step - loss: 0.6462 - accuracy: 0.2160 - val_loss: 1.7321 - val_accuracy: 0.1746\n","Epoch 29/50\n","35/35 [==============================] - 13s 381ms/step - loss: 0.6288 - accuracy: 0.2176 - val_loss: 1.8797 - val_accuracy: 0.1581\n","Epoch 30/50\n","35/35 [==============================] - 14s 400ms/step - loss: 0.6211 - accuracy: 0.2186 - val_loss: 1.7681 - val_accuracy: 0.1728\n","Epoch 31/50\n","35/35 [==============================] - 12s 351ms/step - loss: 0.6008 - accuracy: 0.2201 - val_loss: 1.8383 - val_accuracy: 0.1668\n","Epoch 32/50\n","35/35 [==============================] - 12s 347ms/step - loss: 0.5904 - accuracy: 0.2219 - val_loss: 1.8048 - val_accuracy: 0.1712\n","Epoch 33/50\n","35/35 [==============================] - 12s 345ms/step - loss: 0.5705 - accuracy: 0.2236 - val_loss: 1.8548 - val_accuracy: 0.1628\n","Epoch 34/50\n","35/35 [==============================] - 12s 345ms/step - loss: 0.5608 - accuracy: 0.2255 - val_loss: 1.8094 - val_accuracy: 0.1733\n","Epoch 35/50\n","35/35 [==============================] - 12s 348ms/step - loss: 0.5577 - accuracy: 0.2261 - val_loss: 1.8182 - val_accuracy: 0.1729\n","Epoch 36/50\n","35/35 [==============================] - 12s 342ms/step - loss: 0.5336 - accuracy: 0.2289 - val_loss: 1.8419 - val_accuracy: 0.1701\n","Epoch 37/50\n","35/35 [==============================] - 12s 342ms/step - loss: 0.5260 - accuracy: 0.2291 - val_loss: 1.7766 - val_accuracy: 0.1797\n","Epoch 38/50\n","35/35 [==============================] - 12s 346ms/step - loss: 0.5117 - accuracy: 0.2319 - val_loss: 1.8153 - val_accuracy: 0.1776\n","Epoch 39/50\n","35/35 [==============================] - 13s 363ms/step - loss: 0.4935 - accuracy: 0.2338 - val_loss: 1.8149 - val_accuracy: 0.1777\n","Epoch 40/50\n","35/35 [==============================] - 12s 353ms/step - loss: 0.4911 - accuracy: 0.2346 - val_loss: 1.8577 - val_accuracy: 0.1751\n","Epoch 41/50\n","35/35 [==============================] - 12s 347ms/step - loss: 0.4783 - accuracy: 0.2358 - val_loss: 1.9969 - val_accuracy: 0.1574\n","Epoch 42/50\n","35/35 [==============================] - 12s 347ms/step - loss: 0.4671 - accuracy: 0.2384 - val_loss: 1.8370 - val_accuracy: 0.1804\n","Epoch 43/50\n","35/35 [==============================] - 12s 344ms/step - loss: 0.4556 - accuracy: 0.2398 - val_loss: 1.8573 - val_accuracy: 0.1778\n","Epoch 44/50\n","35/35 [==============================] - 12s 347ms/step - loss: 0.4474 - accuracy: 0.2405 - val_loss: 1.8507 - val_accuracy: 0.1814\n","Epoch 45/50\n","35/35 [==============================] - 12s 351ms/step - loss: 0.4332 - accuracy: 0.2441 - val_loss: 1.9110 - val_accuracy: 0.1753\n","Epoch 46/50\n","35/35 [==============================] - 12s 346ms/step - loss: 0.4182 - accuracy: 0.2432 - val_loss: 1.9650 - val_accuracy: 0.1637\n","Epoch 47/50\n","35/35 [==============================] - 12s 345ms/step - loss: 0.4318 - accuracy: 0.2432 - val_loss: 1.9426 - val_accuracy: 0.1719\n","Epoch 48/50\n","35/35 [==============================] - 12s 344ms/step - loss: 0.3992 - accuracy: 0.2491 - val_loss: 1.9154 - val_accuracy: 0.1753\n","Epoch 49/50\n","35/35 [==============================] - 12s 345ms/step - loss: 0.3985 - accuracy: 0.2482 - val_loss: 1.9339 - val_accuracy: 0.1760\n","Epoch 50/50\n","35/35 [==============================] - 12s 348ms/step - loss: 0.3923 - accuracy: 0.2504 - val_loss: 1.9312 - val_accuracy: 0.1769\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f930e49ab90>"]},"metadata":{},"execution_count":55}],"source":["# %load training_model.py\n","\n","# Choose a dimensionality\n","latent_dim = 400\n","# compresses the dimensions of the latent space \n","# (dimensionality decreases before it increases again (Encoder and Decoder respectively))\n","\n","# Choose a batch size\n","# and a larger number of epochs:\n","batch_size = 40\n","# batch size defines the number of samples that will be propagated through the network\n","# batch size < overall size of all the samples\n","# less memory since we train the network using fewer samples\n","# typically networks train faster with mini-batches,\n","# because after each propagation the weights are updated\n","# the smaller the batch, the less accurate the gradient will be\n","\n","epochs = 50\n","# one epoch = one forward pass and one backward pass of all the training examples\n","\n","# Encoder training setup\n","encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","encoder_lstm = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n","encoder_states = [state_hidden, state_cell]\n","\n","# Decoder training setup:\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Building the training model:\n","training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","print(\"Model summary:\\n\")\n","training_model.summary()\n","print(\"\\n\\n\")\n","\n","# Compile the model:\n","training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# print(\"Training the model:\\n\")\n","# Train the model:\n","training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.3)\n","# validation_split = 0.2 ==> the amount of that that will be used as validation data\n","# the model will set apart this amount of data, won't train on this and eventually it will measure\n","# the loss of any model metrics on this data at the end of each epoch.\n","\n"]},{"cell_type":"code","source":["training_model.save('content/drive/MyDrive/NLP/C_A_Machine_Translation_Project/CodeAcademy_Project/machine_translation_project/training_model2.h5')"],"metadata":{"id":"fqEMLVkNIpO5"},"id":"fqEMLVkNIpO5","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"0EMLX89pNdtx"},"id":"0EMLX89pNdtx"},{"cell_type":"code","execution_count":null,"id":"fe8fa935","metadata":{"id":"fe8fa935"},"outputs":[],"source":["import sys\n","import os"]},{"cell_type":"code","source":["import sys\n","test_function = sys.path.insert(0,\"/content/drive/MyDrive/NLP/C_A_Machine_Translation_Project/CodeAcademy_Project/machine_translation_project/test_function.py\")"],"metadata":{"id":"Kx7XoMQ7Etpo"},"id":"Kx7XoMQ7Etpo","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.saving.hdf5_format import load_model_from_hdf5\n","import numpy as np\n","import tensorflow as tf\n","\n","training_model = load_model_from_hdf5(\"/content/content/drive/MyDrive/NLP/C_A_Machine_Translation_Project/CodeAcademy_Project/machine_translation_project/training_model2.h5\")\n","encoder_inputs = training_model.input[0]\n","encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n","encoder_states = [state_h_enc, state_c_enc]\n","\n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","\n","decoder_state_input_hidden = Input(shape=(latent_dim,))\n","decoder_state_input_cell = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n","decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_hidden, state_cell]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n","\n","def decode_sequence(test_input):\n","  # Encode the input as state vectors.\n","  states_value = encoder_model.predict(test_input)\n","\n","  # Generate empty target sequence of length 1.\n","  target_seq = np.zeros((1, 1, num_decoder_tokens))\n","  # Populate the first token of target sequence with the start token.\n","  target_seq[0, 0, target_features_dict['<START>']] = 1.\n","\n","  # Sampling loop for a batch of sequences\n","  # (to simplify, here we assume a batch of size 1).\n","  decoded_sentence = ''\n","\n","  stop_condition = False\n","  while not stop_condition:\n","    # Run the decoder model to get possible \n","    # output tokens (with probabilities) & states\n","    output_tokens, hidden_state, cell_state = decoder_model.predict(\n","      [target_seq] + states_value)\n","\n","    # Choose token with highest probability\n","    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","    sampled_token = reverse_target_features_dict[sampled_token_index]\n","    decoded_sentence += \" \" + sampled_token\n","\n","    # Exit condition: either hit max length\n","    # or find stop token.\n","    if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n","      stop_condition = True\n","\n","    # Update the target sequence (of length 1).\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    target_seq[0, 0, sampled_token_index] = 1.\n","\n","    # Update states\n","    states_value = [hidden_state, cell_state]\n","\n","  return decoded_sentence\n","\n","\n","# CHANGE RANGE (NUMBER OF TEST SENTENCES TO TRANSLATE) AS YOU PLEASE\n","for seq_index in range(50):\n","  test_input = encoder_input_data[seq_index: seq_index + 1]\n","  decoded_sentence = decode_sequence(test_input)\n","  print('-')\n","  print('Input sentence:', input_docs[seq_index])\n","  print('Decoded sentence:', decoded_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PBewqs05E0ZG","executionInfo":{"status":"ok","timestamp":1649154506194,"user_tz":-120,"elapsed":13119,"user":{"displayName":"Paschalis Agapitos","userId":"16267825236843228607"}},"outputId":"7c1375d7-5a3b-43aa-8143-3c5f421cb368"},"id":"PBewqs05E0ZG","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-\n","Input sentence: Go.\n","Decoded sentence:  Προσπαθούμε .\n","-\n","Input sentence: Go.\n","Decoded sentence:  Προσπαθούμε .\n","-\n","Input sentence: Run!\n","Decoded sentence:  Τέλεια ! <END>\n","-\n","Input sentence: Run!\n","Decoded sentence:  Τέλεια ! <END>\n","-\n","Input sentence: Run.\n","Decoded sentence:  Τρέχα . <END>\n","-\n","Input sentence: Who?\n","Decoded sentence:  Ψαρεύεις ; <END>\n","-\n","Input sentence: Wow!\n","Decoded sentence:  Βιάσου ! <END>\n","-\n","Input sentence: Duck!\n","Decoded sentence:  Βιάσου ! <END>\n","-\n","Input sentence: Duck!\n","Decoded sentence:  Βιάσου ! <END>\n","-\n","Input sentence: Help!\n","Decoded sentence:  Σήκω ! <END>\n","-\n","Input sentence: Jump!\n","Decoded sentence:  Πήδα ! <END>\n","-\n","Input sentence: Hello!\n","Decoded sentence:  Γεια σας . <END>\n","-\n","Input sentence: Hurry!\n","Decoded sentence:  Βιάσου ! <END>\n","-\n","Input sentence: I try.\n","Decoded sentence:  Προσπαθώ . <END>\n","-\n","Input sentence: I won!\n","Decoded sentence:  Κέρδισα ! <END>\n","-\n","Input sentence: I won!\n","Decoded sentence:  Κέρδισα ! <END>\n","-\n","Input sentence: Smile.\n","Decoded sentence:  Χαμογέλα . <END>\n","-\n","Input sentence: Attack!\n","Decoded sentence:  Σοβαρέψου ! <END>\n","-\n","Input sentence: Cheers!\n","Decoded sentence:  Στην υγειά ! <END>\n","-\n","Input sentence: I fell.\n","Decoded sentence:  Έπεσα . <END>\n","-\n","Input sentence: I know.\n","Decoded sentence:  Γέλασα . <END>\n","-\n","Input sentence: I left.\n","Decoded sentence:  Έφυγα . <END>\n","-\n","Input sentence: I lied.\n","Decoded sentence:  Είπα ψέματα .\n","-\n","Input sentence: I lost.\n","Decoded sentence:  Έχασα . <END>\n","-\n","Input sentence: I'm OK.\n","Decoded sentence:  Είμαι καλά . <END>\n","-\n","Input sentence: I'm OK.\n","Decoded sentence:  Είμαι καλά . <END>\n","-\n","Input sentence: I'm OK.\n","Decoded sentence:  Είμαι καλά . <END>\n","-\n","Input sentence: Listen.\n","Decoded sentence:  Άκου . <END>\n","-\n","Input sentence: No way!\n","Decoded sentence:  Έλα τίποτα ! <END>\n","-\n","Input sentence: Really?\n","Decoded sentence:  Αλήθεια ; <END>\n","-\n","Input sentence: Thanks.\n","Decoded sentence:  Ευχαριστώ . <END>\n","-\n","Input sentence: Try it.\n","Decoded sentence:  Με το . <END>\n","-\n","Input sentence: Try it.\n","Decoded sentence:  Με το . <END>\n","-\n","Input sentence: We try.\n","Decoded sentence:  Προσπαθούμε .\n","-\n","Input sentence: We won.\n","Decoded sentence:  Χάνουμε . <END>\n","-\n","Input sentence: We won.\n","Decoded sentence:  Χάνουμε . <END>\n","-\n","Input sentence: Why me?\n","Decoded sentence:  Πόσο εκνευριστικό\n","-\n","Input sentence: Ask Tom.\n","Decoded sentence:  Ρωτήστε τον Τομ\n","-\n","Input sentence: Ask Tom.\n","Decoded sentence:  Ρωτήστε τον Τομ\n","-\n","Input sentence: Get Tom.\n","Decoded sentence:  Πιάστε τον Τομ\n","-\n","Input sentence: Get Tom.\n","Decoded sentence:  Πιάστε τον Τομ\n","-\n","Input sentence: Get Tom.\n","Decoded sentence:  Πιάστε τον Τομ\n","-\n","Input sentence: Get Tom.\n","Decoded sentence:  Πιάστε τον Τομ\n","-\n","Input sentence: Get out!\n","Decoded sentence:  Όνειρα γλυκά !\n","-\n","Input sentence: Get out.\n","Decoded sentence:  Βγείτε έξω . <END>\n","-\n","Input sentence: Get out.\n","Decoded sentence:  Βγείτε έξω . <END>\n","-\n","Input sentence: Goodbye!\n","Decoded sentence:  Αντίο . <END>\n","-\n","Input sentence: He came.\n","Decoded sentence:  Άκου . <END>\n","-\n","Input sentence: He runs.\n","Decoded sentence:  Αυτός είναι .\n","-\n","Input sentence: Help me!\n","Decoded sentence:  Βοήθησέ με ! <END>\n"]}]},{"cell_type":"markdown","source":["Future work:\n","\n","Add in a step to convert new text into a NumPy matrix so that you can translate new sentences that aren’t in the dataset. (This may also require handling unknown tokens.)"],"metadata":{"id":"JYhfYreiPshB"},"id":"JYhfYreiPshB"},{"cell_type":"code","source":[""],"metadata":{"id":"z9Z0DBjEPvxY"},"id":"z9Z0DBjEPvxY","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"machine_translation_project.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}